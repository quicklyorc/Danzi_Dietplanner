{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyP9eLt4r65azdxYY4OpVaOh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXv6xPmwXw1c","executionInfo":{"status":"ok","timestamp":1718260875579,"user_tz":-540,"elapsed":2765,"user":{"displayName":"pass life (lifepass)","userId":"00968563824678792718"}},"outputId":"945a3441-1f4b-4e05-b6ab-0494324e0931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tqdm import tqdm\n","from PIL import Image\n","import glob\n","# 기본 데이터 경로\n","import os\n","base_path = '/content/drive/MyDrive/YANG/unzip/images/crop'\n","\n","before_YANG_loc = '/content/drive/MyDrive/'\n","\n","foodfolders = glob.glob(base_path + \"/*\")\n","\n","\n","img_size = (224, 224)\n","dw1 = pd.DataFrame(columns=[\"path\", \"quantity\",\"ratio\"])\n","\n","save_path = \"/content/drive/MyDrive/YANG/unzip/images/resize_dw1\"\n","\n","for foodfolder in tqdm(foodfolders[:-2]):\n","    foodname = foodfolder.split(\"\\\\\")[-1]\n","    labeldf = pd.read_csv(foodfolder+f\"/{foodname}_train.csv\")\n","\n","    SorT = [\"side\", \"top\"]\n","    Qn = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n","    intQn = {\"Q1\":1, \"Q2\":2, \"Q3\":3, \"Q4\":4, \"Q5\":5}\n","\n","    for st in SorT:\n","        for qn in Qn:\n","\n","            # filtered_df = labeldf[labeldf['filename'].apply(lambda x: x.split(\"_\")[1]) == st and (labeldf['quantity'] == qn)].iloc[:20, :]\n","            filtered_df = labeldf[(labeldf['filename'].apply(lambda x: x.split(\"_\")[1]) == st) & (labeldf['quantity'] == qn)].iloc[:22, :]\n","\n","            for i in filtered_df.index:\n","                filename = filtered_df[\"filename\"][i]\n","                image_path = filtered_df[\"filepath\"][i]\n","                quantity = filtered_df[\"quantity\"][i]\n","                ratio = filtered_df[\"ratio\"][i]\n","                try:\n","                    img_read = Image.open(before_YANG_loc + image_path)\n","                except:\n","                    print(image_path)\n","                    continue\n","                img_arr = np.array(img_read)\n","\n","                img = cv2.resize(img_arr, img_size)\n","\n","                os.makedirs(save_path, exist_ok=True)\n","\n","                image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","                path = save_path + f\"/resize_{filename}\"\n","\n","                filepath = f\"/YANG/unzip/images/resize_dw1/resize_{filename}\"\n","                dw1.loc[len(dw1)] = [filepath,quantity,ratio]\n","\n","                ptype = os.path.splitext(path)[1]\n","                ret, img_arr = cv2.imencode(ptype, image_rgb)\n","\n","                if ret:\n","                    with open(path, mode='w+b') as f:\n","                        img_arr.tofile(f)\n","dw1.to_csv(before_YANG_loc + \"YANG/unzip/images/resize_dw1/dw1.csv\", index=False)"],"metadata":{"id":"0rMfH9yuDkDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYfhukN-XtWp","executionInfo":{"status":"ok","timestamp":1718260616334,"user_tz":-540,"elapsed":3787892,"user":{"displayName":"pass life (lifepass)","userId":"00968563824678792718"}},"outputId":"a82821c9-a2a6-4ae4-f95d-7dd52c3bcef6"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 83/83 [1:03:07<00:00, 45.63s/it]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tqdm import tqdm\n","from PIL import Image\n","import glob\n","# 기본 데이터 경로\n","import os\n","base_path = '/content/drive/MyDrive/YANG/unzip/images/crop_fix'\n","\n","before_YANG_loc = '/content/drive/MyDrive/'\n","\n","foodfolders = glob.glob(base_path + \"/*\")\n","\n","\n","img_size = (224, 224)\n","dw2 = pd.DataFrame(columns=[\"path\", \"quantity\"])\n","\n","save_path = \"/content/drive/MyDrive/YANG/unzip/images/resize_dw2\"\n","\n","for foodfolder in tqdm(foodfolders[:-1]):\n","    foodname = foodfolder.split(\"/\")[-1]\n","    labeldf = pd.read_csv(foodfolder+f\"/{foodname}_train.csv\")\n","\n","    SorT = [\"side\", \"top\"]\n","    Qn = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q5\"]\n","    intQn = {\"Q1\":1, \"Q2\":2, \"Q3\":3, \"Q4\":4, \"Q5\":5}\n","\n","    for st in SorT:\n","        for qn in Qn:\n","\n","            # filtered_df = labeldf[labeldf['filename'].apply(lambda x: x.split(\"_\")[1]) == st and (labeldf['quantity'] == qn)].iloc[:20, :]\n","            filtered_df = labeldf[(labeldf['filename'].apply(lambda x: x.split(\"_\")[1]) == st) & (labeldf['quantity'] == qn)].iloc[:22, :]\n","\n","            for i in filtered_df.index:\n","                filename = filtered_df[\"filename\"][i]\n","                image_path = filtered_df[\"filepath\"][i]\n","                quantity = filtered_df[\"quantity\"][i]\n","                try:\n","                    img_read = Image.open(before_YANG_loc + image_path)\n","                except:\n","                    print(image_path)\n","                    continue\n","                img_arr = np.array(img_read)\n","\n","                img = cv2.resize(img_arr, img_size)\n","\n","                os.makedirs(save_path, exist_ok=True)\n","\n","                image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","                path = save_path + f\"/resize_{filename}\"\n","\n","                filepath = f\"/YANG/unzip/images/resize_dw2/resize_{filename}\"\n","                dw2.loc[len(dw2)] = [filepath,quantity]\n","\n","                ptype = os.path.splitext(path)[1]\n","                ret, img_arr = cv2.imencode(ptype, image_rgb)\n","\n","                if ret:\n","                    with open(path, mode='w+b') as f:\n","                        img_arr.tofile(f)\n","dw2.to_csv(before_YANG_loc + \"YANG/unzip/images/resize_dw2/dw2.csv\", index=False)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tqdm import tqdm\n","from PIL import Image\n","import glob\n","import os\n","\n","# base_path = 'G:/내 드라이브/YANG/unzip/images/crop'\n","\n","before_YANG_loc = '/content/drive/MyDrive/'\n","\n","imgs = []\n","target = []\n","target_int = []\n","\n","labeldf = pd.read_csv(before_YANG_loc + \"YANG/unzip/images/resize_dw1/dw1.csv\")\n","\n","for i in labeldf.index:\n","    image_path = labeldf[\"path\"][i]\n","    quantity = labeldf[\"quantity\"][i]\n","    try:\n","        img_read = Image.open(before_YANG_loc + image_path)\n","    except:\n","        print(image_path)\n","        continue\n","    img_arr = np.array(img_read)\n","\n","    imgs.append(img_arr)\n","    target_int.append(intQn[quantity])\n","    target.append(quantity)\n","\n","imgs = np.array(imgs)/255.0\n","target_int = np.array(target_int)\n","target = np.array(target)\n","target_cat = np.array(pd.get_dummies(target))"],"metadata":{"id":"eKO284e1X4D_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터와 타겟을 파일로 저장\n","np.save('/content/drive/MyDrive/YANG/npy/new/imgs.npy', imgs)\n","# np.save('/content/drive/MyDrive/YANG/npy/new/ratios.npy', ratios)\n","np.save('/content/drive/MyDrive/YANG/npy/new/target.npy', target_cat)\n","np.save('/content/drive/MyDrive/npy/new/target_int.npy', target_int)"],"metadata":{"id":"YtQ1WdZrX_it"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tqdm import tqdm\n","from PIL import Image\n","import glob\n","\n","imgdf = pd.read_csv(\"/content/drive/MyDrive/YANG/unzip/images/resize_dw2/dw2.csv\")\n","data = imgdf.to_dict(orient='records')\n","\n","\n","imgs = []\n","\n","for item in tqdm(data):\n","  img = cv2.imread(\"/content/drive/MyDrive\"+item['path'])\n","  imgs.append(img)\n","\n","o_imgs = np.array(imgs)/255.0\n","n_imgs = o_imgs.astype(np.float32)\n","print(\"imgs shape:\", n_imgs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmgrSFA6mQIS","executionInfo":{"status":"ok","timestamp":1718261269206,"user_tz":-540,"elapsed":200033,"user":{"displayName":"pass life (lifepass)","userId":"00968563824678792718"}},"outputId":"9e43905c-8ce7-487d-c802-045eb8939371"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 18260/18260 [02:31<00:00, 120.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["imgs shape: (18260, 224, 224, 3)\n"]}]},{"cell_type":"code","source":["target = []\n","\n","for item in tqdm(data):\n","  target.append(item['quantity'])\n","\n","target = np.array(target)\n","print(\"target shape:\", target.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSIu29Z_noJf","executionInfo":{"status":"ok","timestamp":1718261279036,"user_tz":-540,"elapsed":318,"user":{"displayName":"pass life (lifepass)","userId":"00968563824678792718"}},"outputId":"a36f0427-92ef-48b7-e012-85036628d78e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 18260/18260 [00:00<00:00, 2814803.60it/s]"]},{"output_type":"stream","name":"stdout","text":["target shape: (18260,)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["np.save('/content/drive/MyDrive/YANG/npy/new/img_n_cropfix.npy', n_imgs)\n","np.save('/content/drive/MyDrive/YANG/npy/new/img_cropfix.npy', imgs)\n","np.save('/content/drive/MyDrive/YANG/npy/new/label_cropfix.npy', target)"],"metadata":{"id":"iPNUVr22oHPj"},"execution_count":null,"outputs":[]}]}